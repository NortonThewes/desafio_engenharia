{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "729a8b77-2abe-4146-b91c-bd612eb3a6c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Session criada com sucesso.\n",
      "Iniciando a leitura das tabelas do Data Warehouse...\n",
      "Lendo 'fato_movimentacao_cartao' e registrando como view 'fato'...\n",
      "Lendo 'dim_associado' e registrando como view 'dim_associado'...\n",
      "Lendo 'dim_cartao' e registrando como view 'dim_cartao'...\n",
      "Lendo 'dim_conta' e registrando como view 'dim_conta'...\n",
      "Views temporárias criadas com sucesso.\n",
      "Executando a query SQL para gerar a visão flat...\n",
      "Amostra dos dados gerados:\n",
      "+--------------+-------------------+---------------+-----------------------+-----------------------+-------------------+-------------+--------------------+-------------------+----------+------------------+\n",
      "|nome_associado|sobrenome_associado|idade_associado|vlr_transacao_movimento|des_transacao_movimento|data_movimentacao  |numero_cartao|nome_impresso_cartao|data_criacao_cartao|tipo_conta|data_criacao_conta|\n",
      "+--------------+-------------------+---------------+-----------------------+-----------------------+-------------------+-------------+--------------------+-------------------+----------+------------------+\n",
      "|LUCAS         |MARTINS            |41             |110.00                 |MOV-311                |2025-08-14 20:25:00|000211       |NOME 211            |2024-01-08         |CORRENTE  |2019-05-26        |\n",
      "|ANA           |SILVA              |40             |55.75                  |MOV-301                |2025-08-14 10:30:00|000201       |NOME 201            |2023-01-15         |CORRENTE  |2019-02-20        |\n",
      "|ANA           |SILVA              |40             |10.99                  |MOV-312                |2025-08-15 09:30:00|000201       |NOME 201            |2023-01-15         |CORRENTE  |2019-02-20        |\n",
      "|ANA           |SILVA              |40             |120.00                 |MOV-302                |2025-08-14 11:45:00|000202       |NOME 202            |2023-01-15         |CORRENTE  |2019-02-20        |\n",
      "|FERNANDA      |ALVES              |35             |30.50                  |MOV-310                |2025-08-14 19:10:00|000210       |NOME 210            |2023-07-30         |CORRENTE  |2023-01-17        |\n",
      "+--------------+-------------------+---------------+-----------------------+-----------------------+-------------------+-------------+--------------------+-------------------+----------+------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Iniciando a escrita do arquivo CSV em: -f\n",
      "Arquivo flat gerado com sucesso!\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import sys \n",
    "\n",
    "# --- 1. Configurações e Constantes ---\n",
    "JAR_PATH = \"/opt/spark/jars/postgresql-42.7.3.jar\"\n",
    "DB_URL = \"jdbc:postgresql://db:5432/SiCooperativeDW\"\n",
    "DB_PROPERTIES = {\n",
    "    \"user\": \"user\",\n",
    "    \"password\": \"password\",\n",
    "    \"driver\": \"org.postgresql.Driver\",\n",
    "}\n",
    "\n",
    "# Dicionário com as tabelas do DW e os nomes que usaremos no SQL\n",
    "TABLES_TO_REGISTER = {\n",
    "    \"fato_movimentacao_cartao\": \"fato\",\n",
    "    \"dim_associado\": \"dim_associado\",\n",
    "    \"dim_cartao\": \"dim_cartao\",\n",
    "    \"dim_conta\": \"dim_conta\"\n",
    "}\n",
    "\n",
    "if len(sys.argv) < 2:\n",
    "    print(\"Erro: O caminho do diretório de saída não foi fornecido.\")\n",
    "    print(\"Uso: spark-submit seu_script.py /caminho/de/saida/no/container\")\n",
    "    sys.exit(1) # Encerra o script com erro\n",
    "\n",
    "# Pega o primeiro argumento passado pelo usuário para ser o diretório de saída\n",
    "OUTPUT_PATH = sys.argv[1]\n",
    "\n",
    "\n",
    "def get_spark_session():\n",
    "    \"\"\"\n",
    "    Cria e retorna uma SparkSession configurada.\n",
    "    \"\"\"\n",
    "    return (\n",
    "        SparkSession.builder.appName(\"DW to Flat File Exporter - Spark SQL\")\n",
    "        .config(\"spark.jars\", JAR_PATH)\n",
    "        .getOrCreate()\n",
    "    )\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Função principal que executa o processo de exportação.\n",
    "    \"\"\"\n",
    "    spark = get_spark_session()\n",
    "    print(\"Spark Session criada com sucesso.\")\n",
    "\n",
    "    # --- 2. Leitura das Tabelas e Registro das Views ---\n",
    "    # Lemos cada tabela do PostgreSQL e a registramos como uma view temporária\n",
    "    # para que o Spark SQL possa encontrá-la.\n",
    "    print(\"Iniciando a leitura das tabelas do Data Warehouse...\")\n",
    "    for db_table, view_name in TABLES_TO_REGISTER.items():\n",
    "        print(f\"Lendo '{db_table}' e registrando como view '{view_name}'...\")\n",
    "        df = spark.read.jdbc(url=DB_URL, table=db_table, properties=DB_PROPERTIES)\n",
    "        df.createOrReplaceTempView(view_name)\n",
    "    \n",
    "    print(\"Views temporárias criadas com sucesso.\")\n",
    "\n",
    "    # --- 3. Transformação com uma Única Query Spark SQL ---\n",
    "    # Esta é a query que \"achata\" o Star Schema, juntando a fato com as dimensões.\n",
    "    # A lógica é a mesma do script anterior, mas agora dentro de uma string SQL.\n",
    "    \n",
    "    flatten_sql_query = \"\"\"\n",
    "        SELECT\n",
    "            -- Colunas da dim_associado\n",
    "            da.nome_associado,\n",
    "            da.sobrenome_associado,\n",
    "            da.idade_atual_associado as idade_associado,\n",
    "            \n",
    "            -- Colunas da fato\n",
    "            f.valor_movimentacao    AS vlr_transacao_movimento,\n",
    "            f.id_movimentacao_cartao  AS des_transacao_movimento, -- Usando o ID como descrição\n",
    "            f.data_movimentacao,\n",
    "\n",
    "            -- Colunas da dim_cartao\n",
    "            dc.numero_cartao,\n",
    "            dc.nome_impresso_cartao,\n",
    "            dc.data_emissao_cartao as data_criacao_cartao,\n",
    "\n",
    "            -- Colunas da dim_conta\n",
    "            dcn.tipo_conta,\n",
    "            dcn.data_criacao_conta\n",
    "        FROM\n",
    "            fato AS f\n",
    "        INNER JOIN\n",
    "            dim_associado AS da ON f.SK_Associado = da.SK_Associado\n",
    "        INNER JOIN\n",
    "            dim_cartao AS dc ON f.SK_Cartao = dc.SK_Cartao\n",
    "        INNER JOIN\n",
    "            dim_conta AS dcn ON f.SK_Conta = dcn.SK_Conta\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Executando a query SQL para gerar a visão flat...\")\n",
    "    movimento_flat_df = spark.sql(flatten_sql_query)\n",
    "\n",
    "    print(\"Amostra dos dados gerados:\")\n",
    "    movimento_flat_df.show(5, truncate=False)\n",
    "\n",
    "    # --- Escrita do Arquivo de Saída (usa a variável OUTPUT_PATH) ---\n",
    "    print(f\"Iniciando a escrita do arquivo CSV em: {OUTPUT_PATH}\")\n",
    "    movimento_flat_df.coalesce(1).write.format(\"csv\").option(\n",
    "        \"header\", \"true\"\n",
    "    ).option(\n",
    "        \"sep\", \";\"\n",
    "    ).mode(\n",
    "        \"overwrite\"\n",
    "    ).save(OUTPUT_PATH)\n",
    "    print(\"Arquivo flat gerado com sucesso!\")\n",
    "    \n",
    "    spark.stop()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44996786-f716-47eb-9e03-e0caf666f689",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
